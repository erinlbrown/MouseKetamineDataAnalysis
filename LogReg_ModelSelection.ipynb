{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "Loading required package: foreach\n",
      "Loaded glmnet 2.0-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(boot)\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv(\"trainC.csv\")\n",
    "test <- read.csv(\"testC.csv\")\n",
    "train <- subset(train, select = -c(sessionDate, trialNum, timeSinceKetamine, animalName))\n",
    "test <- subset(test, select = -c(sessionDate, trialNum, timeSinceKetamine, animalName))\n",
    "\n",
    "#TRAIN 1: ALL COVARIATES PLUS INTERACTION TERMS\n",
    "train1 <- read.csv(\"trainC.csv\")\n",
    "test1 <- read.csv(\"testC.csv\")\n",
    "train1 <- subset(train1, select = -c(sessionDate, trialNum, timeSinceKetamine, animalName))\n",
    "test1 <- subset(test1, select = -c(sessionDate, trialNum, timeSinceKetamine, animalName))\n",
    "\n",
    "#TRAIN 2: ALL COVARIATES NO INTERACTION TERMS\n",
    "train2 <- subset(train1, select = c(totalCellNum,gender,genotype,weight_g,ketamine_day,\n",
    "                                    correlationScore,lickAccuracy,lickNumber,avgFR,\n",
    "                                    avgSingleCellVariance,varianceFR,avgTrialSpeed,\n",
    "                                    varianceSpeed,medianCellDepth,ketBool))\n",
    "test2 <- subset(test1, select = c(totalCellNum,gender,genotype,weight_g,ketamine_day,\n",
    "                                    correlationScore,lickAccuracy,lickNumber,avgFR,\n",
    "                                    avgSingleCellVariance,varianceFR,avgTrialSpeed,\n",
    "                                    varianceSpeed,medianCellDepth,ketBool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's do a 50% split on the training data to determine the best lambda\n",
    "n = length(train[,1])\n",
    "n50 = round(n/2)\n",
    "train50A = train[1:n50,]\n",
    "train50B = train[(n50+1):n,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Logistic Regression Model with Interaction Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Logistic Regression Model with Interaction Terms\n",
      "\n",
      "Zero-One Loss (10-fold Cross-Validation Average): 0.09182746 \n",
      "Accuracy (10-fold Cross-Validation Average): 0.9081725 \n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n = length(train1[,1])\n",
    "fsize = round(n/k)\n",
    "rmse = rep(0,k)\n",
    "zoloss = rep(0,k)\n",
    "for (i in 1:(k-1)){\n",
    "    # Get train and validation sets\n",
    "    df_train <- train1[-(((i-1)*fsize+1):(i*fsize)),]\n",
    "    df_val <- train1[((i-1)*fsize+1):(i*fsize),]\n",
    "    # Fit model on training and make predictions on validation\n",
    "    model_cv <- glm(ketBool ~ ., data=df_train, family='binomial')\n",
    "    lr_pred_lo <- predict(model_cv,df_val) # lo : log odds\n",
    "    num_val = length(df_val$ketBool)\n",
    "    lr_pred = rep(0,num_val)\n",
    "    actual = rep(0,num_val)\n",
    "    for (j in 1:num_val){\n",
    "        if (lr_pred_lo[j]>0){\n",
    "            lr_pred[j]=1\n",
    "        }\n",
    "    actual[j] = df_val$ketBool[j]\n",
    "    }\n",
    "    # Compute 0-1 loss for each observation\n",
    "    lr_loss = abs(lr_pred-actual) # loss is 0 if NB_pred=actual, 1 otherwise\n",
    "    # Compute mean 0-1 loss on the val set\n",
    "    zoloss[i] = mean(lr_loss)\n",
    "}\n",
    "df_train <- train1[-(((k-1)*fsize+1):n),]\n",
    "df_val <- train1[((k-1)*fsize+1):n,]\n",
    "# Fit model on training and make predictions on validation\n",
    "model_cv <- glm(ketBool ~ ., data=df_train, family='binomial')\n",
    "lr_pred_lo <- predict(model_cv,df_val) # lo : log odds\n",
    "num_val = length(df_val$ketBool)\n",
    "lr_pred = rep(0,num_val)\n",
    "actual = rep(0,num_val)\n",
    "for (j in 1:num_val){\n",
    "    if (lr_pred_lo[j]>0){\n",
    "        lr_pred[j]=1\n",
    "    }\n",
    "    actual[j] = df_val$ketBool[j]\n",
    "}\n",
    "lr_loss = abs(lr_pred-actual)\n",
    "zoloss[k] = mean(lr_loss)\n",
    "test_error_est = mean(zoloss)\n",
    "\n",
    "cat(\"=====================================================================\\n\")\n",
    "cat(\"Logistic Regression Model with Interaction Terms\\n\\n\")\n",
    "cat(\"Zero-One Loss (10-fold Cross-Validation Average):\",test_error_est,\"\\n\")\n",
    "cat(\"Accuracy (10-fold Cross-Validation Average):\",1-test_error_est,\"\\n\")\n",
    "cat(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced dataset to match Lasso and Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Logistic Regression Model with Interaction Terms\n",
      "\n",
      "Zero-One Loss (10-fold Cross-Validation Average): 0.09505025 \n",
      "Accuracy (10-fold Cross-Validation Average): 0.9049497 \n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n = length(train50B[,1])\n",
    "fsize = round(n/k)\n",
    "rmse = rep(0,k)\n",
    "zoloss = rep(0,k)\n",
    "for (i in 1:(k-1)){\n",
    "    # Get train and validation sets\n",
    "    df_train <- train50B[-(((i-1)*fsize+1):(i*fsize)),]\n",
    "    df_val <- train50B[((i-1)*fsize+1):(i*fsize),]\n",
    "    # Fit model on training and make predictions on validation\n",
    "    model_cv <- glm(ketBool ~ ., data=df_train, family='binomial')\n",
    "    lr_pred_lo <- predict(model_cv,df_val) # lo : log odds\n",
    "    num_val = length(df_val$ketBool)\n",
    "    lr_pred = rep(0,num_val)\n",
    "    actual = rep(0,num_val)\n",
    "    for (j in 1:num_val){\n",
    "        if (lr_pred_lo[j]>0){\n",
    "            lr_pred[j]=1\n",
    "        }\n",
    "    actual[j] = df_val$ketBool[j]\n",
    "    }\n",
    "    # Compute 0-1 loss for each observation\n",
    "    lr_loss = abs(lr_pred-actual) # loss is 0 if NB_pred=actual, 1 otherwise\n",
    "    # Compute mean 0-1 loss on the val set\n",
    "    zoloss[i] = mean(lr_loss)\n",
    "}\n",
    "df_train <- train50B[-(((k-1)*fsize+1):n),]\n",
    "df_val <- train50B[((k-1)*fsize+1):n,]\n",
    "# Fit model on training and make predictions on validation\n",
    "model_cv <- glm(ketBool ~ ., data=df_train, family='binomial')\n",
    "lr_pred_lo <- predict(model_cv,df_val) # lo : log odds\n",
    "num_val = length(df_val$ketBool)\n",
    "lr_pred = rep(0,num_val)\n",
    "actual = rep(0,num_val)\n",
    "for (j in 1:num_val){\n",
    "    if (lr_pred_lo[j]>0){\n",
    "        lr_pred[j]=1\n",
    "    }\n",
    "    actual[j] = df_val$ketBool[j]\n",
    "}\n",
    "lr_loss = abs(lr_pred-actual)\n",
    "zoloss[k] = mean(lr_loss)\n",
    "test_error_est = mean(zoloss)\n",
    "\n",
    "cat(\"=====================================================================\\n\")\n",
    "cat(\"Logistic Regression Model with Interaction Terms\\n\\n\")\n",
    "cat(\"Zero-One Loss (10-fold Cross-Validation Average):\",test_error_est,\"\\n\")\n",
    "cat(\"Accuracy (10-fold Cross-Validation Average):\",1-test_error_est,\"\\n\")\n",
    "cat(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Logistic Regression without Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Logistic Regression Model without Interaction Terms\n",
      "\n",
      "Zero-One Loss (10-fold Cross-Validation Average): 0.1413709 \n",
      "Accuracy (10-fold Cross-Validation Average): 0.8586291 \n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n = length(train2[,1])\n",
    "fsize = round(n/k)\n",
    "rmse = rep(0,k)\n",
    "zoloss = rep(0,k)\n",
    "for (i in 1:(k-1)){\n",
    "    # Get train and validation sets\n",
    "    df_train <- train2[-(((i-1)*fsize+1):(i*fsize)),]\n",
    "    df_val <- train2[((i-1)*fsize+1):(i*fsize),]\n",
    "    # Fit model on training and make predictions on validation\n",
    "    model_cv <- glm(ketBool ~ ., data=df_train, family='binomial')\n",
    "    lr_pred_lo <- predict(model_cv,df_val) # lo : log odds\n",
    "    num_val = length(df_val$ketBool)\n",
    "    lr_pred = rep(0,num_val)\n",
    "    actual = rep(0,num_val)\n",
    "    for (j in 1:num_val){\n",
    "        if (lr_pred_lo[j]>0){\n",
    "            lr_pred[j]=1\n",
    "        }\n",
    "    actual[j] = df_val$ketBool[j]\n",
    "    }\n",
    "    # Compute 0-1 loss for each observation\n",
    "    lr_loss = abs(lr_pred-actual) # loss is 0 if NB_pred=actual, 1 otherwise\n",
    "    # Compute mean 0-1 loss on the val set\n",
    "    zoloss[i] = mean(lr_loss)\n",
    "}\n",
    "df_train <- train2[-(((k-1)*fsize+1):n),]\n",
    "df_val <- train2[((k-1)*fsize+1):n,]\n",
    "# Fit model on training and make predictions on validation\n",
    "model_cv <- glm(ketBool ~ ., data=df_train, family='binomial')\n",
    "lr_pred_lo <- predict(model_cv,df_val) # lo : log odds\n",
    "num_val = length(df_val$ketBool)\n",
    "lr_pred = rep(0,num_val)\n",
    "actual = rep(0,num_val)\n",
    "for (j in 1:num_val){\n",
    "    if (lr_pred_lo[j]>0){\n",
    "        lr_pred[j]=1\n",
    "    }\n",
    "    actual[j] = df_val$ketBool[j]\n",
    "}\n",
    "lr_loss = abs(lr_pred-actual)\n",
    "zoloss[k] = mean(lr_loss)\n",
    "test_error_est = mean(zoloss)\n",
    "\n",
    "cat(\"=====================================================================\\n\")\n",
    "cat(\"Logistic Regression Model without Interaction Terms\\n\\n\")\n",
    "cat(\"Zero-One Loss (10-fold Cross-Validation Average):\",test_error_est,\"\\n\")\n",
    "cat(\"Accuracy (10-fold Cross-Validation Average):\",1-test_error_est,\"\\n\")\n",
    "cat(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLMNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's do a 50% split on the training data to determine the best lambda\n",
    "n = length(train[,1])\n",
    "n50 = round(n/2)\n",
    "train50A = train[1:n50,]\n",
    "train50B = train[(n50+1):n,]\n",
    "\n",
    "xA = as.matrix(train50A[,-length(train50A)])\n",
    "yA = as.matrix(train50A$ketBool)\n",
    "xB = as.matrix(train50B[,-length(train50B)])\n",
    "yB = as.matrix(train50B$ketBool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select regularization parameter over trainA (50% of training data)\n",
    "model_lasso <- cv.glmnet(xA, yA, family='binomial',alpha=1)\n",
    "lambda_min = model_lasso$lambda.min\n",
    "lambda_1se = model_lasso$lambda.1se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "GLMNET Lasso Logistic Regression Model with lambda.min\n",
      "\n",
      "Zero-One Loss (10-fold Cross-Validation Average): 0.09205025 \n",
      "Accuracy (10-fold Cross-Validation Average): 0.9079497 \n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n = length(train50B[,1])\n",
    "fsize = round(n/k)\n",
    "rmse = rep(0,k)\n",
    "zoloss = rep(0,k)\n",
    "for (i in 1:(k-1)){\n",
    "    # Get train and validation sets\n",
    "    xB_train = xB[-(((i-1)*fsize+1):(i*fsize)),]\n",
    "    yB_train = yB[-(((i-1)*fsize+1):(i*fsize)),]\n",
    "    xB_val = xB[((i-1)*fsize+1):(i*fsize),]\n",
    "    yB_val = yB[((i-1)*fsize+1):(i*fsize),]\n",
    "    # Fit model on training and make predictions on validation\n",
    "    model_cv <- glmnet(xB_train, yB_train, family='binomial',alpha=1,lambda=lambda_min)\n",
    "    pred_lo = predict(model_cv, newx = xB_val)\n",
    "    num_val = length(yB_val)\n",
    "    lr_pred = rep(0,num_val)\n",
    "    actual = rep(0,num_val)\n",
    "    for (j in 1:num_val){\n",
    "        if (pred_lo[j]>0){\n",
    "            lr_pred[j]=1\n",
    "        }\n",
    "        actual[j] = yB_val[j]\n",
    "    }\n",
    "    # Compute 0-1 loss for each observation\n",
    "    lr_loss = abs(lr_pred-actual) # loss is 0 if NB_pred=actual, 1 otherwise\n",
    "    # Compute mean 0-1 loss on the val set\n",
    "    zoloss[i] = mean(lr_loss)\n",
    "}\n",
    "xB_train = xB[-(((k-1)*fsize+1):(length(yB))),]\n",
    "yB_train = yB[-(((k-1)*fsize+1):(length(yB))),]\n",
    "xB_val = xB[((k-1)*fsize+1):(length(yB)),]\n",
    "yB_val = yB[((k-1)*fsize+1):(length(yB)),]\n",
    "# Fit model on training and make predictions on validation\n",
    "model_cv <- glmnet(xB_train, yB_train, family='binomial',alpha=1,lambda=lambda_min)\n",
    "pred_lo = predict(model_cv, newx = xB_val)\n",
    "num_val = length(yB_val)\n",
    "lr_pred = rep(0,num_val)\n",
    "actual = rep(0,num_val)\n",
    "for (j in 1:num_val){\n",
    "    if (pred_lo[j]>0){\n",
    "        lr_pred[j]=1\n",
    "    }\n",
    "    actual[j] = yB_val[j]\n",
    "}\n",
    "# Compute 0-1 loss for each observation\n",
    "lr_loss = abs(lr_pred-actual) # loss is 0 if NB_pred=actual, 1 otherwise\n",
    "# Compute mean 0-1 loss on the val set\n",
    "zoloss[k] = mean(lr_loss)\n",
    "test_error_est = mean(zoloss)\n",
    "\n",
    "cat(\"=====================================================================\\n\")\n",
    "cat(\"GLMNET Lasso Logistic Regression Model with lambda.min\\n\\n\")\n",
    "cat(\"Zero-One Loss (10-fold Cross-Validation Average):\",test_error_est,\"\\n\")\n",
    "cat(\"Accuracy (10-fold Cross-Validation Average):\",1-test_error_est,\"\\n\")\n",
    "cat(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select regularization parameter over trainA (50% of training data)\n",
    "model_lasso <- cv.glmnet(xA, yA, family='binomial',alpha=0)\n",
    "lambda_min = model_lasso$lambda.min\n",
    "lambda_1se = model_lasso$lambda.1se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "GLMNET Ridge Logistic Regression Model with lambda.min\n",
      "\n",
      "Zero-One Loss (10-fold Cross-Validation Average): 0.1260879 \n",
      "Accuracy (10-fold Cross-Validation Average): 0.8739121 \n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n = length(train50B[,1])\n",
    "fsize = round(n/k)\n",
    "rmse = rep(0,k)\n",
    "zoloss = rep(0,k)\n",
    "for (i in 1:(k-1)){\n",
    "    # Get train and validation sets\n",
    "    xB_train = xB[-(((i-1)*fsize+1):(i*fsize)),]\n",
    "    yB_train = yB[-(((i-1)*fsize+1):(i*fsize)),]\n",
    "    xB_val = xB[((i-1)*fsize+1):(i*fsize),]\n",
    "    yB_val = yB[((i-1)*fsize+1):(i*fsize),]\n",
    "    # Fit model on training and make predictions on validation\n",
    "    model_cv <- glmnet(xB_train, yB_train, family='binomial',alpha=0,lambda=lambda_min)\n",
    "    pred_lo = predict(model_cv, newx = xB_val)\n",
    "    num_val = length(yB_val)\n",
    "    lr_pred = rep(0,num_val)\n",
    "    actual = rep(0,num_val)\n",
    "    for (j in 1:num_val){\n",
    "        if (pred_lo[j]>0){\n",
    "            lr_pred[j]=1\n",
    "        }\n",
    "        actual[j] = yB_val[j]\n",
    "    }\n",
    "    # Compute 0-1 loss for each observation\n",
    "    lr_loss = abs(lr_pred-actual) # loss is 0 if NB_pred=actual, 1 otherwise\n",
    "    # Compute mean 0-1 loss on the val set\n",
    "    zoloss[i] = mean(lr_loss)\n",
    "}\n",
    "xB_train = xB[-(((k-1)*fsize+1):(length(yB))),]\n",
    "yB_train = yB[-(((k-1)*fsize+1):(length(yB))),]\n",
    "xB_val = xB[((k-1)*fsize+1):(length(yB)),]\n",
    "yB_val = yB[((k-1)*fsize+1):(length(yB)),]\n",
    "# Fit model on training and make predictions on validation\n",
    "model_cv <- glmnet(xB_train, yB_train, family='binomial',alpha=0,lambda=lambda_min)\n",
    "pred_lo = predict(model_cv, newx = xB_val)\n",
    "num_val = length(yB_val)\n",
    "lr_pred = rep(0,num_val)\n",
    "actual = rep(0,num_val)\n",
    "for (j in 1:num_val){\n",
    "    if (pred_lo[j]>0){\n",
    "        lr_pred[j]=1\n",
    "    }\n",
    "    actual[j] = yB_val[j]\n",
    "}\n",
    "# Compute 0-1 loss for each observation\n",
    "lr_loss = abs(lr_pred-actual) # loss is 0 if NB_pred=actual, 1 otherwise\n",
    "# Compute mean 0-1 loss on the val set\n",
    "zoloss[k] = mean(lr_loss)\n",
    "test_error_est = mean(zoloss)\n",
    "\n",
    "cat(\"=====================================================================\\n\")\n",
    "cat(\"GLMNET Ridge Logistic Regression Model with lambda.min\\n\\n\")\n",
    "cat(\"Zero-One Loss (10-fold Cross-Validation Average):\",test_error_est,\"\\n\")\n",
    "cat(\"Accuracy (10-fold Cross-Validation Average):\",1-test_error_est,\"\\n\")\n",
    "cat(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
