{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Logistic Regression on Mouse Ketamine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "from numpy import squeeze\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.read_csv('sessionTrialTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['animalName', 'sessionDate', 'trialNum', 'totalCellNum', 'gender',\n",
       "       'genotype', 'weight_g', 'ketamine_day', 'correlationScore',\n",
       "       'lickAccuracy', 'lickNumber', 'avgFR', 'avgSingleCellVariance',\n",
       "       'varianceFR', 'avgTrialSpeed', 'varianceSpeed', 'medianCellDepth',\n",
       "       'timeSinceKetamine', 'ketamineAdministered'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols = 19\n",
      "num_rows = 5000\n",
      "num_dup = 0\n"
     ]
    }
   ],
   "source": [
    "# Check size information\n",
    "print(\"num_cols =\",len(allData.keys()))\n",
    "print(\"num_rows =\",len(allData))\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"num_dup =\",np.sum(pd.DataFrame.duplicated(allData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animalName               0\n",
       "sessionDate              0\n",
       "trialNum                 0\n",
       "totalCellNum             0\n",
       "gender                   0\n",
       "genotype                 0\n",
       "weight_g                 0\n",
       "ketamine_day             0\n",
       "correlationScore         0\n",
       "lickAccuracy             0\n",
       "lickNumber               0\n",
       "avgFR                    1\n",
       "avgSingleCellVariance    1\n",
       "varianceFR               3\n",
       "avgTrialSpeed            0\n",
       "varianceSpeed            0\n",
       "medianCellDepth          0\n",
       "timeSinceKetamine        0\n",
       "ketamineAdministered     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaNs and see where they are coming from\n",
    "np.sum(pd.isna(allData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Drop NaN\n",
      "num_rows = 4997\n"
     ]
    }
   ],
   "source": [
    "# Simply drop any rows with nans since we have so few\n",
    "allDataNN = pd.DataFrame.dropna(allData,'index')\n",
    "print(\"After Drop NaN\")\n",
    "print(\"num_rows =\",len(allDataNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ketBool = allDataNN['ketamineAdministered']\n",
    "timeSinceKetamine = allDataNN['timeSinceKetamine']\n",
    "sessionDate = allDataNN['sessionDate']\n",
    "trialNum = allDataNN['trialNum']\n",
    "neuralData = allDataNN[['animalName', 'totalCellNum',\n",
    "       'gender', 'genotype', 'weight_g',\n",
    "       'ketamine_day', 'correlationScore', 'lickAccuracy',\n",
    "       'lickNumber', 'avgFR', 'avgSingleCellVariance',\n",
    "       'varianceFR', 'avgTrialSpeed', 'varianceSpeed',\n",
    "       'medianCellDepth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns\n",
    "le = LabelEncoder()\n",
    "neuralData_LE = neuralData.copy()\n",
    "neuralData_LE['animalName'] = le.fit_transform(neuralData_LE['animalName'])\n",
    "neuralData_LE['gender'] = le.fit_transform(neuralData_LE['gender'])\n",
    "neuralData_LE['genotype'] = le.fit_transform(neuralData_LE['genotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(neuralData_LE,ketBool.values.ravel(), test_size=0.2)\n",
    "# Now we save X_test and y_test for next part of the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for cross validation, use 10 folds\n",
    "num_folds = 10\n",
    "XA = np.array(X)\n",
    "yA = np.array(y)\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "skf = StratifiedKFold(n_splits=num_folds)\n",
    "for train_index, test_index in skf.split(XA, yA):\n",
    "    X_train.append(XA[train_index])\n",
    "    X_test.append(XA[test_index])\n",
    "    y_train.append(yA[train_index])\n",
    "    y_test.append(yA[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1848886664998749\n",
      "0.16562421816362272\n",
      "0.15186389792344257\n",
      "0.14836127095321494\n",
      "0.14535901926444839\n",
      "0.14786089567175387\n",
      "0.14961220915686768\n",
      "0.14660995746810113\n",
      "0.14660995746810113\n"
     ]
    }
   ],
   "source": [
    "# Run basic log reg model on train set, check performance against train\n",
    "# Run model, tuning over C_param (l2 penalty by default)\n",
    "for C_param in [0.01, 0.1, 1, 10, 100, 1000, 5000, 10000, 50000]:\n",
    "    model = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000,C = C_param).fit(X, y) \n",
    "    y_pred = model.predict(X)\n",
    "    print(zero_one_loss(y, y_pred))\n",
    "# Let's use C = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best loss was at C=10000, so let's use that! Note that the resulting loss score was 0.1411."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average zero-one loss across folds: 0.14660081313008205\n",
      "Average accuracy across folds: 0.8533991868699179\n"
     ]
    }
   ],
   "source": [
    "C_param = 10000\n",
    "zo_loss = []\n",
    "accuracy = []\n",
    "num_folds=10\n",
    "for i in range(0,num_folds):\n",
    "    LRmodel = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000, C = C_param).fit(X_train[i], y_train[i]) \n",
    "    y_pred = model.predict(X_test[i])\n",
    "    zo_loss.append(zero_one_loss(y_test[i],y_pred))\n",
    "    accuracy.append(accuracy_score(y_test[i],y_pred))\n",
    "\n",
    "avg_zo_loss = np.mean(zo_loss)\n",
    "avg_acc = np.mean(accuracy)\n",
    "print(\"Average zero-one loss across folds:\",avg_zo_loss)\n",
    "print(\"Average accuracy across folds:\",avg_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average zero-one loss across 10-fold CV was 0.1466, only very slightly worse than our overall training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now try with standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/browne/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/browne/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "stdNeuralData = StandardScaler().fit_transform(neuralData_LE) \n",
    "X, X_test, y, y_test = train_test_split(stdNeuralData,ketBool.values.ravel(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for cross validation, use 10 folds\n",
    "num_folds = 10\n",
    "XA = np.array(X)\n",
    "yA = np.array(y)\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "skf = StratifiedKFold(n_splits=num_folds)\n",
    "for train_index, test_index in skf.split(XA, yA):\n",
    "    X_train.append(XA[train_index])\n",
    "    X_test.append(XA[test_index])\n",
    "    y_train.append(yA[train_index])\n",
    "    y_test.append(yA[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1553665248936702\n",
      "0.15061295971978983\n",
      "0.14836127095321494\n",
      "0.14786089567175387\n",
      "0.14811108331248435\n",
      "0.14811108331248435\n"
     ]
    }
   ],
   "source": [
    "# Run basic log reg model on train set, check performance against train\n",
    "# Run model, tuning over C_param (l2 penalty by default)\n",
    "for C_param in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    model = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000,C = C_param).fit(X, y) \n",
    "    y_pred = model.predict(X)\n",
    "    print(zero_one_loss(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best loss was at C=10, so let's use that! Note that the resulting loss score was 0.1471."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average zero-one loss across folds: 0.1481146616541353\n",
      "Average accuracy across folds: 0.8518853383458647\n"
     ]
    }
   ],
   "source": [
    "C_param = 10\n",
    "zo_loss = []\n",
    "accuracy = []\n",
    "num_folds=10\n",
    "for i in range(0,num_folds):\n",
    "    LRmodel = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000, C = C_param).fit(X_train[i], y_train[i]) \n",
    "    y_pred = model.predict(X_test[i])\n",
    "    zo_loss.append(zero_one_loss(y_test[i],y_pred))\n",
    "    accuracy.append(accuracy_score(y_test[i],y_pred))\n",
    "\n",
    "avg_zo_loss = np.mean(zo_loss)\n",
    "avg_acc = np.mean(accuracy)\n",
    "print(\"Average zero-one loss across folds:\",avg_zo_loss)\n",
    "print(\"Average accuracy across folds:\",avg_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average zero-one loss across 10-fold CV was 0.1471, the same within significant digits as our overall training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET CHECKS - FOR LATER\n",
    "# Make predictions# Let's use C = 100\n",
    "#y_pred = model.predict(X_test)\n",
    "# Keep prediction probability, not using for now, consider adding a threshold\n",
    "#y_pred_proba = model.predict_proba(X_test)\n",
    "#print(zero_one_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now with augmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugData = neuralData_LE.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugData['animalNamexCorrelationScore'] = AugData['animalName']*AugData['correlationScore']\n",
    "AugData['animalNamexLickAccuracy'] = AugData['animalName']*AugData['lickAccuracy']\n",
    "AugData['animalNamexLickNumber'] = AugData['animalName']*AugData['lickNumber']\n",
    "AugData['animalNamexAvgFR'] = AugData['animalName']*AugData['avgFR']\n",
    "AugData['animalNamexAvgSingleCellVariance'] = AugData['animalName']*AugData['avgSingleCellVariance']\n",
    "AugData['animalNamexVarianceFR'] = AugData['animalName']*AugData['varianceFR']\n",
    "AugData['animalNamexAvgTrialSpeed'] = AugData['animalName']*AugData['avgTrialSpeed']\n",
    "AugData['animalNamexVarianceSpeed'] = AugData['animalName']*AugData['varianceSpeed']\n",
    "\n",
    "AugData['totalCellNumxCorrelationScore'] = AugData['totalCellNum']*AugData['correlationScore']\n",
    "AugData['totalCellNumxLickAccuracy'] = AugData['totalCellNum']*AugData['lickAccuracy']\n",
    "AugData['totalCellNumxLickNumber'] = AugData['totalCellNum']*AugData['lickNumber']\n",
    "AugData['totalCellNumxAvgFR'] = AugData['totalCellNum']*AugData['avgFR']\n",
    "AugData['totalCellNumxAvgSingleCellVariance'] = AugData['totalCellNum']*AugData['avgSingleCellVariance']\n",
    "AugData['totalCellNumxVarianceFR'] = AugData['totalCellNum']*AugData['varianceFR']\n",
    "AugData['totalCellNumxAvgTrialSpeed'] = AugData['totalCellNum']*AugData['avgTrialSpeed']\n",
    "AugData['totalCellNumxVarianceSpeed'] = AugData['totalCellNum']*AugData['varianceSpeed']\n",
    "\n",
    "AugData['genderxCorrelationScore'] = AugData['gender']*AugData['correlationScore']\n",
    "AugData['genderxLickAccuracy'] = AugData['gender']*AugData['lickAccuracy']\n",
    "AugData['genderxLickNumber'] = AugData['gender']*AugData['lickNumber']\n",
    "AugData['genderxAvgFR'] = AugData['gender']*AugData['avgFR']\n",
    "AugData['genderxAvgSingleCellVariance'] = AugData['gender']*AugData['avgSingleCellVariance']\n",
    "AugData['genderxVarianceFR'] = AugData['gender']*AugData['varianceFR']\n",
    "AugData['genderxAvgTrialSpeed'] = AugData['gender']*AugData['avgTrialSpeed']\n",
    "AugData['genderxVarianceSpeed'] = AugData['gender']*AugData['varianceSpeed']\n",
    "\n",
    "AugData['genotypexCorrelationScore'] = AugData['genotype']*AugData['correlationScore']\n",
    "AugData['genotypexLickAccuracy'] = AugData['genotype']*AugData['lickAccuracy']\n",
    "AugData['genotypexLickNumber'] = AugData['genotype']*AugData['lickNumber']\n",
    "AugData['genotypexAvgFR'] = AugData['genotype']*AugData['avgFR']\n",
    "AugData['genotypexAvgSingleCellVariance'] = AugData['genotype']*AugData['avgSingleCellVariance']\n",
    "AugData['genotypexVarianceFR'] = AugData['genotype']*AugData['varianceFR']\n",
    "AugData['genotypexAvgTrialSpeed'] = AugData['genotype']*AugData['avgTrialSpeed']\n",
    "AugData['genotypexVarianceSpeed'] = AugData['genotype']*AugData['varianceSpeed']\n",
    "\n",
    "AugData['weight_gxCorrelationScore'] = AugData['weight_g']*AugData['correlationScore']\n",
    "AugData['weight_gxLickAccuracy'] = AugData['weight_g']*AugData['lickAccuracy']\n",
    "AugData['weight_gxLickNumber'] = AugData['weight_g']*AugData['lickNumber']\n",
    "AugData['weight_gxAvgFR'] = AugData['weight_g']*AugData['avgFR']\n",
    "AugData['weight_gxAvgSingleCellVariance'] = AugData['weight_g']*AugData['avgSingleCellVariance']\n",
    "AugData['weight_gxVarianceFR'] = AugData['weight_g']*AugData['varianceFR']\n",
    "AugData['weight_gxAvgTrialSpeed'] = AugData['weight_g']*AugData['avgTrialSpeed']\n",
    "AugData['weight_gxVarianceSpeed'] = AugData['weight_g']*AugData['varianceSpeed']\n",
    "\n",
    "AugData['ketamine_dayxCorrelationScore'] = AugData['ketamine_day']*AugData['correlationScore']\n",
    "AugData['ketamine_dayxLickAccuracy'] = AugData['ketamine_day']*AugData['lickAccuracy']\n",
    "AugData['ketamine_dayxLickNumber'] = AugData['ketamine_day']*AugData['lickNumber']\n",
    "AugData['ketamine_dayxAvgFR'] = AugData['ketamine_day']*AugData['avgFR']\n",
    "AugData['ketamine_dayxAvgSingleCellVariance'] = AugData['ketamine_day']*AugData['avgSingleCellVariance']\n",
    "AugData['ketamine_dayxVarianceFR'] = AugData['ketamine_day']*AugData['varianceFR']\n",
    "AugData['ketamine_dayxAvgTrialSpeed'] = AugData['ketamine_day']*AugData['avgTrialSpeed']\n",
    "AugData['ketamine_dayxVarianceSpeed'] = AugData['ketamine_day']*AugData['varianceSpeed']\n",
    "\n",
    "AugData['medianCellDepthxCorrelationScore'] = AugData['medianCellDepth']*AugData['correlationScore']\n",
    "AugData['medianCellDepthxLickAccuracy'] = AugData['medianCellDepth']*AugData['lickAccuracy']\n",
    "AugData['medianCellDepthxLickNumber'] = AugData['medianCellDepth']*AugData['lickNumber']\n",
    "AugData['medianCellDepthxAvgFR'] = AugData['medianCellDepth']*AugData['avgFR']\n",
    "AugData['medianCellDepthxAvgSingleCellVariance'] = AugData['medianCellDepth']*AugData['avgSingleCellVariance']\n",
    "AugData['medianCellDepthxVarianceFR'] = AugData['medianCellDepth']*AugData['varianceFR']\n",
    "AugData['medianCellDepthxAvgTrialSpeed'] = AugData['medianCellDepth']*AugData['avgTrialSpeed']\n",
    "AugData['medianCellDepthxVarianceSpeed'] = AugData['medianCellDepth']*AugData['varianceSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/browne/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/browne/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "stdNeuralDataAug = StandardScaler().fit_transform(AugData) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(stdNeuralDataAug,ketBool.values.ravel(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for cross validation, use 10 folds\n",
    "num_folds = 10\n",
    "XA = np.array(X)\n",
    "yA = np.array(y)\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "skf = StratifiedKFold(n_splits=num_folds)\n",
    "for train_index, test_index in skf.split(XA, yA):\n",
    "    X_train.append(XA[train_index])\n",
    "    X_test.append(XA[test_index])\n",
    "    y_train.append(yA[train_index])\n",
    "    y_test.append(yA[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12109081811358524\n",
      "0.09582186639979984\n",
      "0.08006004503377528\n",
      "0.07305479109332003\n",
      "0.07305479109332003\n",
      "0.07230422817112836\n",
      "0.07205404053039777\n"
     ]
    }
   ],
   "source": [
    "# Run basic log reg model on train set, check performance against train\n",
    "# Run model, tuning over C_param (l2 penalty by default)\n",
    "for C_param in [0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "    model = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000,C = C_param).fit(X, y) \n",
    "    y_pred = model.predict(X)\n",
    "    print(zero_one_loss(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average zero-one loss across folds: 0.07204581176559488\n",
      "Average accuracy across folds: 0.927954188234405\n"
     ]
    }
   ],
   "source": [
    "C_param = 1000\n",
    "zo_loss = []\n",
    "accuracy = []\n",
    "num_folds=10\n",
    "for i in range(0,num_folds):\n",
    "    LRmodel = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000, C = C_param).fit(X_train[i], y_train[i]) \n",
    "    y_pred = model.predict(X_test[i])\n",
    "    zo_loss.append(zero_one_loss(y_test[i],y_pred))\n",
    "    accuracy.append(accuracy_score(y_test[i],y_pred))\n",
    "\n",
    "avg_zo_loss = np.mean(zo_loss)\n",
    "avg_acc = np.mean(accuracy)\n",
    "print(\"Average zero-one loss across folds:\",avg_zo_loss)\n",
    "print(\"Average accuracy across folds:\",avg_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(solver='lbfgs',max_iter=1000,C = 10000).fit(X, y) \n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07205404053039777"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_one_loss(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279459594696022"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = cm[0,0]\n",
    "fn = cm[1,0]\n",
    "tp = cm[1,1]\n",
    "fp = cm[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1832"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1877"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1832,  136],\n",
       "       [ 152, 1877]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3997"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1832+152+136+1877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
